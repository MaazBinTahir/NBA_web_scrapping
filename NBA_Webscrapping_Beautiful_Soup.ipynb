{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6c02d9",
   "metadata": {},
   "source": [
    "# NBA Data Web-Scrapping using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39468ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcafbef",
   "metadata": {},
   "source": [
    "## MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a996609",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "771cc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"mvp\") # Making a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "afdcb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "years =list(range(2012,2016)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2bc8325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for year in years:\n",
    "    link = url.format(year)\n",
    "    data = requests.get(link) #reading the data\n",
    "    json = data.text # getting into json format\n",
    "    \n",
    "    with open(\"mvp/{}.html\".format(year), \"w\", encoding = \"utf-8\") as f: # writing files on the PC\n",
    "        f.write(json)\n",
    "    \n",
    "    with open(\"mvp/{}.html\".format(year), \"r\", encoding = \"utf-8\") as f: # reading the files from the PC\n",
    "        page= f.read()\n",
    "        html = BeautifulSoup(page, \"html.parser\") # getting html\n",
    "        html.find(\"tr\", class_ ='over_header').decompose() # Dropping multilevel index columns\n",
    "        table = html.find(id = \"mvp\") # finding mvps' table\n",
    "        table = pd.read_html(str(table)) # reading the html file\n",
    "        mvp = table[0] # indexing the required table\n",
    "        mvp[\"Year\"] = year\n",
    "        df.append(mvp)\n",
    "\n",
    "mvps = pd.concat(df)\n",
    "mvps.reset_index(drop= True, inplace = True)\n",
    "mvps.to_csv(\"mvp/mvps.csv\", index = False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b1369",
   "metadata": {},
   "source": [
    "## Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f16db7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "310684a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "483982ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "years =list(range(2012,2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1b05602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for year in years:\n",
    "    link = url.format(year)\n",
    "    data = requests.get(link) #reading the data\n",
    "    json = data.text # getting into json format\n",
    "    \n",
    "    with open(\"players/{}.html\".format(year), \"w\", encoding = \"utf-8\") as f: # writing files on the PC\n",
    "        f.write(json)\n",
    "        \n",
    "    with open(\"players/{}.html\".format(year), \"r\", encoding = \"utf-8\") as f: # reading the files from the PC\n",
    "        page= f.read()\n",
    "    \n",
    "        html = BeautifulSoup(page, \"html.parser\") # getting html\n",
    "        table = html.find(id = \"all_per_game_stats\")\n",
    "        table = pd.read_html(str(table)) # reading the html file\n",
    "        player = table[0] # indexing the required table\n",
    "        player[\"Year\"] = year\n",
    "        df.append(player)\n",
    "\n",
    "players = pd.concat(df)\n",
    "players.reset_index(drop= True, inplace = True)\n",
    "players.to_csv(\"players/players.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a82047",
   "metadata": {},
   "source": [
    "## Division Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f4a2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "68a69e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"divisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a45b7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "years =list(range(2012,2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "76f50897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    link = url.format(year)\n",
    "    data = requests.get(link) #reading the data\n",
    "    json = data.text # getting into json format\n",
    "    \n",
    "    with open(\"divisions/{}.html\".format(year), \"w\", encoding = \"utf-8\") as f: # writing files on the PC\n",
    "        f.write(json)\n",
    "        \n",
    "    with open(\"divisions/{}.html\".format(year), \"r\", encoding = \"utf-8\") as f: # reading the files from the PC\n",
    "        page= f.read()\n",
    "    \n",
    "        html = BeautifulSoup(page, \"html.parser\") # getting html \n",
    "        \n",
    "        \n",
    "        e_table = html.find(id = \"all_divs_standings_E\")\n",
    "        w_table = html.find(id = \"all_divs_standings_W\")\n",
    "        \n",
    "        \n",
    "        e_table = pd.read_html(str(e_table)) # reading the html files\n",
    "        w_table = pd.read_html(str(w_table))\n",
    "        \n",
    "    \n",
    "        est = e_table[0] # indexing the required table\n",
    "        wst = w_table[0]\n",
    "        \n",
    "        est[\"Year\"] = year # adding year\n",
    "        wst[\"Year\"] = year\n",
    "        \n",
    "        df1 = df1.append(est)\n",
    "        df2 = df2.append(wst)\n",
    "\n",
    "df1.rename(columns = {\"Eastern Conference\":\"Team\"}, inplace = True)\n",
    "df2.rename(columns = {\"Western Conference\":\"Team\"}, inplace = True)\n",
    "\n",
    "divisions = pd.concat([df1,df2])\n",
    "divisions.reset_index(drop= True, inplace = True)\n",
    "divisions.to_csv(\"divisions/divisions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b33d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
